#!/bin/bash
#This is Spark installation guide with Jupyter

sudo yum update -y
sudo yum install java-1.8.0-openjdk-devel.x86_64 -y
yum install wget curl -y
yum install vim -y
sudo yum install git -y
sudo yum install htop -y
sudo yum install zsh -y
sh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)"

# add this to /etc/hosts ip-192-168-18-127 -> change to machine dns
192.168.18.178   localhost ip-192-168-18-178

wget http://d3kbcqa49mib13.cloudfront.net/spark-2.0.1-bin-hadoop2.7.tgz
tar -zxvf spark-2.0.1-bin-hadoop2.7.tgz
mv spark-2.0.1-bin-hadoop2.7 spark
export SPARK_HOME=$(pwd)/spark
export PATH=$SPARK_HOME/bin:$PATH
export MASTER_IP=192.168.18.178
#export SPARK_MASTER=spark://$(hostname -i):7077
export SPARK_MASTER=spark://192.168.18.178:7077

# ADD THIS TO YOUR .zshrc FILE
export SPARK_HOME=/root/spark
export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk.x86_64
export PYTHONPATH=/root/spark/python/lib/py4j-0.10.3-src.zip:/root/spark/python
source .zshrc

#Load dependancies
wget http://central.maven.org/maven2/com/amazonaws/aws-java-sdk/1.7.4/aws-java-sdk-1.7.4.jar
wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.7.1/hadoop-aws-2.7.1.jar
wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.6.0/hadoop-aws-2.6.0.jar
wget http://central.maven.org/maven2/mysql/mysql-connector-java/5.1.39/mysql-connector-java-5.1.39.jar
wget https://github.com/s3tools/s3cmd/archive/master.zip
wget http://central.maven.org/maven2/com/databricks/spark-redshift_2.11/2.0.1/spark-redshift_2.11-2.0.1.jar
#Install anaconda
wget https://repo.continuum.io/archive/Anaconda2-4.2.0-Linux-x86_64.sh
bash Anaconda2-4.2.0-Linux-x86_64.sh 
yum install -y centos-release-SCL
yum install -y python27
sudo yum install python-setuptools python-dev build-essential -y
sudo easy_install pip 
sudo pip install numpy
sudo pip install scipy
sudo pip install scikit-learn
sudo pip install pandas
sudo pip install matplotlib



#configure jupyter by this tutorial 
#http://jupyter-notebook.readthedocs.io/en/latest/public_server.html

echo 'export SPARK_HOME='$(pwd)'/spark/'>> ~/.bashrc
echo 'export PATH='$SPARK_HOME'/bin:'$PATH''>> ~/.bashrc
echo 'export MASTER=spark://'$(hostname)':7077'>>~/.bashrc
echo 'export MASTER_IP='$MASTER_IP>>~/.bashrc
